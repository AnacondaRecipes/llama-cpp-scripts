{% set name = "llama.cpp-tools" %}
{% set version = "0.0.3609" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/ggerganov/llama.cpp/archive/b{{ version.split(".")[-1] }}.tar.gz
  sha256: 9545e6cf7052927208538c19ffc97b939876714e4b756542a2c45afb8fd7e581

build:
  entry_points:
    - llama-convert-hf-to-gguf = llama_cpp_tools.convert_hf_to_gguf:main
    - llama-convert-llama-ggml-to-gguf = llama_cpp_tools.convert_llama_ggml_to_gguf:main
    - llama-convert-lora-to-gguf = llama_cpp_tools.convert_lora_to_gguf:main
    - llama-lava-surgery = llama_cpp_tools.examples.llava.llava_surgery:main
    - llama-lava-surgery_v2 = llama_cpp_tools.examples.llava.llava_surgery_v2:main
    - llama-convert-image-encoder-to-gguf = llama_cpp_tools.examples.llava.convert_image_encoder_to_gguf:main
  skip: True # [py<39]
  number: 0

requirements:
  host:
    - python
    - poetry-core >=1.0.0
    - pip
  run:
    - python
    - huggingface_hub >=0.24.6
    - jinja2 >=3.1.4
    - numpy >=1.17
    - protobuf >=3.20.3,<5.0.0
    - pyyaml >=5.1
    - safetensors >=0.4.4
    - sentencepiece >=0.1.96,<0.2.0
    - sqlite >=3.45.3
    - sympy >=1.13.2
    - tk >=8.6.14
    - tokenizers >=0.19.1
    - pytorch >=2.0.0
    - tqdm >=4.66.5
    - transformers >=4.44.1
    - gguf >=0.10.0


test:
  imports:
    - llama_cpp_tools
    - llama_cpp_tools.examples.llava
  commands:
    - llama-convert-hf-to-gguf --help
    - llama-convert-llama-ggml-to-gguf --help
    - llama-convert-lora-to-gguf --help
    - llama-lava-surgery --help
    - llama-lava-surgery_v2 --help
    - llama-convert-image-encoder-to-gguf --help
  requires:
    - pip

about:
  license: MIT
  license_file:
    - LICENSE
    - gguf-py/LICENSE

extra:
  recipe-maintainers:
    - jnoller
